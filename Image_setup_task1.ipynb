{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f12bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b1195c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Path to the dataset\n",
    "data_dir = './Data/Data'\n",
    "\n",
    "# Creating a dataset from the images in the data directory\n",
    "image_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78ed667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train', 'valid']\n"
     ]
    }
   ],
   "source": [
    "# Printing the class names\n",
    "class_names = image_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ef981fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to detect the blurred images\n",
    "def detect_blur(image):\n",
    "  image = tf.cast(image * 255, tf.uint8)  \n",
    "  return tf.py_function(func=_detect_blur, inp=[image], Tout=tf.bool)\n",
    "\n",
    "def _detect_blur(image):\n",
    "  image = image.numpy().copy()\n",
    "  image = np.squeeze(image)\n",
    "  laplacian = cv2.Laplacian(image, cv2.CV_64F)  \n",
    "  laplacian_mean, laplacian_std = cv2.meanStdDev(laplacian)\n",
    "  threshold = laplacian_mean + 3 * laplacian_std  \n",
    "  print(threshold)\n",
    "  print(np.max(laplacian))\n",
    "  return np.max(laplacian) < threshold\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def preprocess_image(image, label):\n",
    "    print(tf.cond(detect_blur(image)\n",
    "                   , true_fn=lambda: (image, label)\n",
    "                   , false_fn=lambda: (tf.zeros_like(image), tf.zeros_like(label))))\n",
    "    return tf.cond(detect_blur(image)\n",
    "                   , true_fn=lambda: (image, label)\n",
    "                   , false_fn=lambda: (tf.zeros_like(image), tf.zeros_like(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88a30def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'cond/Identity:0' shape=(None, 256, 256, 1) dtype=float32>, <tf.Tensor 'cond/Identity_1:0' shape=(None,) dtype=int32>)\n"
     ]
    }
   ],
   "source": [
    "# Detecting and removing the blurred images\n",
    "processed_ds = image_ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "filtered_ds = processed_ds.filter(lambda image, label: tf.math.reduce_all(tf.math.not_equal(image, tf.zeros_like(image))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2071c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio as iio\n",
    " \n",
    "# read an image\n",
    "img = iio.imread(\"images.jpg\") \n",
    "iio.imwrite(\"images.jpg\", img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbe58ca63fe33f9eeae9e71d10368d2b4a57f2b1b395836210cc60d362c66949"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
